{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions for integral image calculation\n",
    "def integral_image(image):\n",
    "    integral = np.cumsum(np.cumsum(image, axis=0), axis=1)\n",
    "    return integral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_integral_sum(integral, x, y, w, h):\n",
    "    a = integral[x, y]\n",
    "    b = integral[x, y + h]\n",
    "    c = integral[x + w, y]\n",
    "    d = integral[x + w, y + h]\n",
    "    return d - b - c + a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Haar-like features\n",
    "def calculate_features(image):\n",
    "    features = []\n",
    "    height, width = image.shape\n",
    "    for w in range(1, width + 1):\n",
    "        for h in range(1, height + 1):\n",
    "            for x in range(width - w + 1):\n",
    "                for y in range(height - h + 1):\n",
    "                    features.append(((x, y, w, h), 1))  # Type 1: Two-rectangle feature\n",
    "                    if w % 2 == 0:\n",
    "                        features.append(((x, y, w, h), 2))  # Type 2: Three-rectangle feature\n",
    "                    if h % 2 == 0:\n",
    "                        features.append(((x, y, w, h), 3))  # Type 3: Four-rectangle feature\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the weak classifiers\n",
    "def train_weak_classifiers(features, images, labels):\n",
    "    num_features = len(features)\n",
    "    num_images = len(images)\n",
    "    num_positives = sum(labels)\n",
    "    num_negatives = num_images - num_positives\n",
    "    pos_weight = 1.0 / (2 * num_positives)\n",
    "    neg_weight = 1.0 / (2 * num_negatives)\n",
    "    classifiers = []\n",
    "\n",
    "    for feat_idx in range(num_features):\n",
    "        feature, feature_type = features[feat_idx]\n",
    "        if feature_type == 1:\n",
    "            threshold = np.mean([get_integral_sum(integral_image(img), *feature) for img in images])\n",
    "        else:\n",
    "            threshold = -np.mean([get_integral_sum(integral_image(img), *feature) for img in images])\n",
    "        error = sum([labels[i] * (get_integral_sum(integral_image(images[i]), *feature) <= threshold) for i in range(num_images)]) * pos_weight + sum([labels[i] * (get_integral_sum(integral_image(images[i]), *feature) > threshold) for i in range(num_images)]) * neg_weight\n",
    "        alpha = 0.5 * np.log((1.0 - error) / max(error, 1e-16))\n",
    "        classifiers.append((feature, threshold, alpha))\n",
    "\n",
    "        # Update image weights\n",
    "        predictions = np.array([get_integral_sum(integral_image(img), *feature) <= threshold for img in images])\n",
    "        labels_float = np.array(labels) * 2.0 - 1.0\n",
    "        weights = np.exp(-alpha * labels_float * predictions)\n",
    "        weights /= np.sum(weights)\n",
    "        labels = list((labels_float + 1.0) / 2.0)\n",
    "\n",
    "    return classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the strong classifier to an image\n",
    "def apply_strong_classifier(image, classifiers):\n",
    "    score = 0.0\n",
    "    for feature, threshold, alpha in classifiers:\n",
    "        if get_integral_sum(integral_image(image), *feature) <= threshold:\n",
    "            score += alpha\n",
    "        else:\n",
    "            score -= alpha\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n\\n(X_train, y_train), (X_test,y_test) = datasets.cifar10.load_data()\\nX_train.shape\\n\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "\n",
    "(X_train, y_train), (X_test,y_test) = datasets.cifar10.load_data()\n",
    "X_train.shape\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nplt.figure(figsize = (15,2))\\nplt.imshow(X_train[0])\\n\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "plt.figure(figsize = (15,2))\n",
    "plt.imshow(X_train[0])\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\n\\ndef load_cifar10():\\n    # Define the transformation to apply to the dataset\\n    transform = transforms.ToTensor()\\n\\n    # Load the CIFAR-10 training dataset\\n    trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\\n    trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\\n\\n    # Get the training images and labels\\n    train_images = []\\n    train_labels = []\\n    for images, labels in trainloader:\\n        train_images.append(images)\\n        train_labels.append(labels)\\n    train_images = torch.cat(train_images, dim=0)\\n    train_labels = torch.cat(train_labels, dim=0)\\n\\n    return train_images, train_labels\\n\\n\\n\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "\n",
    "def load_cifar10():\n",
    "    # Define the transformation to apply to the dataset\n",
    "    transform = transforms.ToTensor()\n",
    "\n",
    "    # Load the CIFAR-10 training dataset\n",
    "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "    # Get the training images and labels\n",
    "    train_images = []\n",
    "    train_labels = []\n",
    "    for images, labels in trainloader:\n",
    "        train_images.append(images)\n",
    "        train_labels.append(labels)\n",
    "    train_images = torch.cat(train_images, dim=0)\n",
    "    train_labels = torch.cat(train_labels, dim=0)\n",
    "\n",
    "    return train_images, train_labels\n",
    "\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def preprocess_cifar10(images):\n",
    "    # Convert pixel values to floats between 0 and 1\n",
    "    #preprocessed_images = images.float() / 255.0\n",
    "\n",
    "    # Normalize the pixel values\n",
    "    mean = torch.tensor([0.4914, 0.4822, 0.4465])  # Mean values for CIFAR-10 dataset\n",
    "    std = torch.tensor([0.2023, 0.1994, 0.2010])  # Standard deviation values for CIFAR-10 dataset\n",
    "    preprocessedd_images = (preprocessedd_images - mean[None, :, None, None]) / std[None, :, None, None]\n",
    "\n",
    "    return preprocessedd_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Preprocess CIFAR-10 dataset (example)\\ndef preprocess_cifar10(images):\\n    # Preprocess CIFAR-10 dataset here\\n    # ...\\n    return preprocessed_images\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Preprocess CIFAR-10 dataset (example)\n",
    "def preprocess_cifar10(images):\n",
    "    # Preprocess CIFAR-10 dataset here\n",
    "    # ...\n",
    "    return preprocessed_images\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Viola-Jones object detector\n",
    "def train_viola_jones(images, labels, num_classifiers):\n",
    "    preprocesseed_images = preprocess_cifar10(images)\n",
    "    integral_images = [integral_image(img) for img in preprocesseed_images]\n",
    "    features = calculate_features(preprocesseed_images[0])\n",
    "    classifiers = train_weak_classifiers(features, integral_images, labels)\n",
    "    sorted_classifiers = sorted(classifiers, key=lambda x: x[2], reverse=True)\n",
    "    return sorted_classifiers[:num_classifiers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the Viola-Jones object detector\n",
    "def test_viola_jones(images, classifiers):\n",
    "    preprocessedddd_images = preprocess_cifar10(images)\n",
    "    predictions = []\n",
    "    for img in preprocessedddd_images:\n",
    "        score = apply_strong_classifier(img, classifiers)\n",
    "        predictions.append(score > 0.0)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'preprocessedd_images' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-15b36cde96a1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_test\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m255.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mclassifiers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_viola_jones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_classifiers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;31m#test_images = load_test_images()  # Load test images\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_viola_jones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassifiers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-14-c7232a009ef6>\u001b[0m in \u001b[0;36mtrain_viola_jones\u001b[1;34m(images, labels, num_classifiers)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Train the Viola-Jones object detector\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtrain_viola_jones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_classifiers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mpreprocesseed_images\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocess_cifar10\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mintegral_images\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mintegral_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpreprocesseed_images\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcalculate_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreprocesseed_images\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-34879aceb816>\u001b[0m in \u001b[0;36mpreprocess_cifar10\u001b[1;34m(images)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mmean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0.4914\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.4822\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.4465\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Mean values for CIFAR-10 dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mstd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0.2023\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.1994\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.2010\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Standard deviation values for CIFAR-10 dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mpreprocessedd_images\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mpreprocessedd_images\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mmean\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mstd\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mpreprocessedd_images\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'preprocessedd_images' referenced before assignment"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "#images, labels = load_cifar10()\n",
    "(X_train, y_train), (X_test,y_test) = datasets.cifar10.load_data()\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "classifiers = train_viola_jones(X_train, y_train, num_classifiers=10)\n",
    "#test_images = load_test_images()  # Load test images\n",
    "predictions = test_viola_jones(X_test, classifiers)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_images, train_labels, test_images, test_labels = load_cifar10()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessed_test_images = preprocess_cifar10(test_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "\n",
    "def load_cifar10():\n",
    "    # Define the transformation to apply to the dataset\n",
    "    transform = transforms.ToTensor()\n",
    "\n",
    "    # Load the CIFAR-10 training dataset\n",
    "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "    # Load the CIFAR-10 test dataset\n",
    "    testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)\n",
    "\n",
    "    # Get the training images and labels\n",
    "    train_images = []\n",
    "    train_labels = []\n",
    "    for images, labels in trainloader:\n",
    "        train_images.append(images)\n",
    "        train_labels.append(labels)\n",
    "    train_images = torch.cat(train_images, dim=0)\n",
    "    train_labels = torch.cat(train_labels, dim=0)\n",
    "\n",
    "    # Get the test images and labels\n",
    "    test_images = []\n",
    "    test_labels = []\n",
    "    for images, labels in testloader:\n",
    "        test_images.append(images)\n",
    "        test_labels.append(labels)\n",
    "    test_images = torch.cat(test_images, dim=0)\n",
    "    test_labels = torch.cat(test_labels, dim=0)\n",
    "\n",
    "    return train_images, train_labels, test_images, test_labels\n",
    "\n",
    "\n",
    "'''\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
